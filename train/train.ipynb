{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets rouge-score nltk -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T05:21:34.559928Z","iopub.execute_input":"2025-06-19T05:21:34.560662Z","iopub.status.idle":"2025-06-19T05:21:41.053081Z","shell.execute_reply.started":"2025-06-19T05:21:34.560630Z","shell.execute_reply":"2025-06-19T05:21:41.052365Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load multi_news dataset\ndataset = load_dataset(\"multi_news\")\n\n# Check keys and example\nprint(dataset)\nprint(dataset[\"train\"][0])\n\n# Extract each split into a variable\ntrain_data = dataset[\"train\"]\nval_data = dataset[\"validation\"]\ntest_data = dataset[\"test\"]\n\n# Optionally, convert to lists of texts and summaries\ntrain_texts = train_data[\"document\"]\ntrain_summaries = train_data[\"summary\"]\n\nval_texts = val_data[\"document\"]\nval_summaries = val_data[\"summary\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T05:21:41.054525Z","iopub.execute_input":"2025-06-19T05:21:41.054793Z","iopub.status.idle":"2025-06-19T05:26:44.056102Z","shell.execute_reply.started":"2025-06-19T05:21:41.054769Z","shell.execute_reply":"2025-06-19T05:26:44.055445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8091a1ace7ae4852b79719889ddb6652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"multi_news.py:   0%|          | 0.00/3.83k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a700ccc0fd4449358333bc7ec6709180"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for multi_news contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/multi_news.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"train.src.cleaned:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf83feb87dd4a57bfeabcdf82aad5b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.tgt:   0%|          | 0.00/58.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66bbcbdbcf0141738da4a2c22fc0ab1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"val.src.cleaned:   0%|          | 0.00/66.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"366cc03fab3f47df89787fc3bc567392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"val.tgt:   0%|          | 0.00/7.30M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d1a796ef5b40cc80f1281f0451c19e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.src.cleaned:   0%|          | 0.00/69.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c209737776c478c824f9166090fc62d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.tgt:   0%|          | 0.00/7.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195a66b6d8ed483a8bfb97eaf711ff17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/44972 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f1ebe1c12e4e108daab2602c185e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5622 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec043366908c47fdaa375a1f63477fd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5622 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e7dead1b684c10a18ac773e48349e0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['document', 'summary'],\n        num_rows: 44972\n    })\n    validation: Dataset({\n        features: ['document', 'summary'],\n        num_rows: 5622\n    })\n    test: Dataset({\n        features: ['document', 'summary'],\n        num_rows: 5622\n    })\n})\n{'document': 'National Archives \\n \\n Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. \\n \\n A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%. \\n \\n Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter. \\n \\n Enjoy the show. ||||| Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work. \\n \\n The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months. \\n \\n The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work. \\n \\n The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending.', 'summary': '– The unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today\\'s jobs report. Reaction on the Wall Street Journal\\'s MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Use appropriate tokenizer (e.g., for BART or T5)\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n\n# Tokenize the dataset\ndef tokenize_fn(example):\n    return tokenizer(example[\"document\"], truncation=True, padding=\"max_length\", max_length=1024)\n\ndef tokenize_target(example):\n    return tokenizer(example[\"summary\"], truncation=True, padding=\"max_length\", max_length=128)\n\ntokenized_train = train_data.map(lambda x: {**tokenize_fn(x), \"labels\": tokenize_target(x)[\"input_ids\"]}, batched=True)\ntokenized_val = val_data.map(lambda x: {**tokenize_fn(x), \"labels\": tokenize_target(x)[\"input_ids\"]}, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T05:26:44.056886Z","iopub.execute_input":"2025-06-19T05:26:44.057527Z","iopub.status.idle":"2025-06-19T05:30:09.769771Z","shell.execute_reply.started":"2025-06-19T05:26:44.057498Z","shell.execute_reply":"2025-06-19T05:30:09.768962Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0b02c3314545158173d1d0df36fbd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe7c95952c114778a75569aa561db2ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d3c7313a91b4844bcc4be4d437a9c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acad7e2e96e746a895535ad49264926a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/44972 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9976c52d63f24430a930d9eac9b76714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5622 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6823ae08a1034851a90f79bf66eb355f"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForSeq2SeqLM\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")\n\n# Training arguments for just 1 epoch\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=1,  # Only one epoch\n    predict_with_generate=True,\n    logging_dir='./logs',\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n)\n\n# Trainer (no early stopping callback)\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer\n)\n\n# Start training\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T06:38:41.538154Z","iopub.execute_input":"2025-06-19T06:38:41.538630Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/50467039.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Save model, tokenizer, and training arguments\ntrainer.save_model(\"./my_trained_model\")\ntokenizer.save_pretrained(\"./my_trained_model\")\nimport shutil\n\n# Zip the folder\nshutil.make_archive(\"my_trained_model\", 'zip', \"./my_trained_model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a download link\nFileLink(\"my_trained_model.zip\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on the validation set\nmetrics = trainer.evaluate()\nprint(metrics)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on the test set\ntest_results = trainer.predict(test_dataset=tokenized_test)\nprint(test_results.metrics)\n# Decode predictions\npred_summaries = tokenizer.batch_decode(\n    test_results.predictions, skip_special_tokens=True\n)\n\n# Optionally view the first few summaries\nfor i in range(10):\n    print(f\"\\nDocument: {test_data[i]['document'][:300]}...\")\n    print(f\"Generated Summary: {pred_summaries[i]}\")\n    print(f\"Reference Summary: {test_data[i]['summary']}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}