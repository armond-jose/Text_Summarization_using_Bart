ğŸ“ BART Text Summarization App
A full-stack AI-powered text summarization tool using a fine-tuned BART model for generating concise summaries from long text.

âœ¨ Features
âœ… AI-Powered Summarization â€“ Converts lengthy text into short, meaningful summaries.
âœ… Fine-Tuned BART Model â€“ Optimized on the Multi-News dataset for high-quality results.
âœ… React Frontend â€“ Modern, responsive UI for seamless user experience.
âœ… FastAPI Backend â€“ Efficient inference using Hugging Face Transformers.
âœ… Deployed on Vercel â€“ Frontend is live for testing.

ğŸš€ Live Demo
ğŸ”— Frontend (Hosted on Vercel):
ğŸ‘‰ https://text-summarization-using-bart-r7g9.vercel.app/

âš ï¸ Backend (Not Publicly Hosted):
Due to the large model size (~1.5GB), the backend must be run locally. Follow the setup guide below.

ğŸ¤– Model Training Details
ğŸ“‚ Dataset Used
Multi-News Dataset (Hugging Face Link)

Contains news summaries and source articles for training.

ğŸ› ï¸ Training Process
Fine-Tuned BART using Hugging Face transformers.

Training script: train/train.ipynb.

Exported model weights to backend/bart_model/.

Inference handled via transformers.pipeline("summarization").

ğŸ“ Project Structure
text
Text_Summarization_using_Bart/
â”œâ”€â”€ train/            # Training scripts & configs
â”œâ”€â”€ dataset/          # Dataset loading scripts
â”œâ”€â”€ backend/          # FastAPI server & BART model
â”‚   â”œâ”€â”€ bart_model/   # Fine-tuned model weights
â”‚   â””â”€â”€ main.py       # FastAPI inference server
â””â”€â”€ frontend/         # React app
ğŸ› ï¸ Local Setup Guide
ğŸ“¥ Clone the Repository
bash
git clone https://github.com/armond-jose/Text_Summarization_using_Bart.git
cd Text_Summarization_using_Bart
ğŸ’» Backend Setup (FastAPI + BART Model)
1. Navigate to the Backend
bash
cd backend
2. (Optional) Create a Virtual Environment
bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
3. Install Dependencies
bash
pip install -r requirements.txt
4. Download & Place Model Weights
Download Model: Google Drive Link (Replace with actual link)

Place model.safetensors inside backend/bart_model/.

5. Run FastAPI Server
bash
uvicorn main:app --host 0.0.0.0 --port 8000
ğŸ”— API Endpoint: http://localhost:8000/summarize